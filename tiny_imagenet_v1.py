# -*- coding: utf-8 -*-
"""tiny_imagenet_v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t46sRNTolEotWoWLndyHs-r4Y-92aXvi
"""

from keras.models import Sequential
from keras.layers.core import Flatten, Dense, Dropout
from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D
from keras.optimizers import SGD
import cv2, numpy as np

from __future__ import print_function
import keras
from keras.datasets import cifar10
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D
from keras.optimizers import SGD
from keras import optimizers
import os
import math
import numpy as np
import scipy
import random
from PIL import Image
import json
from matplotlib import pyplot as plt
from pandas import Series, DataFrame
import datetime

TRAINING_IMAGES_DIR = './tiny-imagenet-200/train/'

import requests
import zipfile
from io import StringIO, BytesIO
import io
def download_images(url):
    if (os.path.isdir(TRAINING_IMAGES_DIR)):
        print ('Images already downloaded...')
        return
    r = requests.get(url, stream=True)
    print ('Downloading ' + url )
    zip_ref = zipfile.ZipFile(BytesIO(r.content))
    zip_ref.extractall('./')
    zip_ref.close()

IMAGES_URL = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'
download_images(IMAGES_URL)

import glob

# path = "/tmp/tiny-imagenet-200/"
path = "./tiny-imagenet-200/"
train_dirs = glob.glob(path + "train/*")
val_dirs   = glob.glob(path + "val/*")
test_dirs  = glob.glob(path + "test/*")

n_samples  = 100000
used_labels =  [ d[-9:] for d in train_dirs ]     # There are only 200 used labels in both training and validation
len(used_labels)

from sklearn.preprocessing import LabelBinarizer # Hot-Encode Labels
bin_encoder = LabelBinarizer()
bin_encoder.fit_transform(used_labels).size

def get_image(img_path):                         # Helper Functions
    img = img_to_array(load_img(img_path))
    return img / 255.0

def get_images(paths):
    n = len(paths)
    X = np.empty(shape=(n, 64,64,3))
    for i,p in enumerate(paths):
        X[i, ...] = get_image(p)
    return X

def shuffle(*args):
    fusion = list(zip(*args))
    np.random.shuffle(fusion)
    return zip(*fusion)
    
def get_model_memory_usage(batch_size, model):
    import numpy as np
    from keras import backend as K

    shapes_mem_count = 0
    for l in model.layers:
        single_layer_mem = 1
        for s in l.output_shape:
            if s is None:
                continue
            single_layer_mem *= s
        shapes_mem_count += single_layer_mem

    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])
    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])

    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)
    gbytes = np.round(total_memory / (1024.0 ** 3), 3)
    return gbytes

## Getting Training Data

train_data_paths, train_labels = [],[]
train_images = np.empty(shape=(n_samples, 64, 64, 3))

for class_path in train_dirs:
    class_name = class_path[-9:]
    images = glob.glob(class_path + '/images/*')
    for image_path in images:
        train_labels    .append( class_name )
        train_data_paths.append( image_path )
        
train_labels, train_data_paths = shuffle(train_labels, train_data_paths)
train_labels = bin_encoder.transform(train_labels) # hot-encode labels from string to number
for i,img_path in enumerate(train_data_paths):     # Load images
    img = get_image(img_path)
    train_images[i, ...] = img
print(len(train_data_paths), train_labels.shape)   # sanity check

## Getting Validation Data
val_labels, val_images_paths = [], []
for line in open(path + 'val/val_annotations.txt'):
    [fn, classname, _ , _, _, _ ] = line.strip().split('\t')
    val_images_paths.append(path +'val/images/' + fn )
    val_labels.append(classname)                   # 10K images probably fit in RAM

val_labels = bin_encoder.transform(val_labels)    # hot-encode labels from string to number
val_images = get_images(val_images_paths)         # use helper function to get all images
print(val_images.shape, val_labels.shape)

# from kernet import resnet
# from vgg16_keras import VGG_16

def add_conv_layer(model, activation, channel_size=16, filter_size=3, input_shape=None, batch_normalization=False):
    if input_shape:
        model.add(Conv2D(channel_size,
                         (filter_size,filter_size),
                         padding='same',
                         input_shape=input_shape))
    else:
        model.add(Conv2D(channel_size, (filter_size,filter_size), padding='same',))
    if batch_normalization:
        model.add(BatchNormalization())
    model.add(Activation(conv_layer_activation))
    model.add(MaxPooling2D(pool_size=(2, 2)))

n_classes  = 200
model = Sequential()

filter_size = 3    # originally, it was 3
conv_layer_activation = 'relu'  # by default, its relu

add_conv_layer(model, conv_layer_activation, 16, filter_size, (64,64,3)) # conv1
add_conv_layer(model, conv_layer_activation, 16, filter_size, batch_normalization=True) # conv2
add_conv_layer(model, conv_layer_activation, 16, filter_size, batch_normalization=True) # conv2-extra
add_conv_layer(model, conv_layer_activation, 32, filter_size, batch_normalization=True) # conv3
add_conv_layer(model, conv_layer_activation, 32, filter_size, batch_normalization=True) # conv4
add_conv_layer(model, conv_layer_activation, 64, filter_size, batch_normalization=True) # conv5

model.add(Flatten())

# fc1
model.add(Dense(1024))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.4))

# fc1-extra
model.add(Dense(512))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.4))

# fc2
model.add(Dense(n_classes))
model.add(Activation('softmax'))

# del model; model = resnet.ResnetBuilder.build((3, 64, 64), 200, 'basic_block', [2, 2, 2, 2])
# del model; model = VGG_16()

# optz = SGD(lr=0.01, momentum=0.9)                                                     # default
# optz = SGD(lr=0.01, momentum=0.9, nesterov=True)
# optz = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)                # https://keras.io/optimizers/
# optz = optimizers.Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)
optz = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)
model.compile(loss='categorical_crossentropy', optimizer=optz, metrics=['accuracy'])

layer_counts = Series([ c['class_name'] for c in model.get_config()]).value_counts()    # layer counts
display(model.summary())

# Settings
epochs = 200
batch_size = 5000
optz_name = str(optz.__class__)[25:-2]
experiement_config = {
    'epochs': epochs, 'batch_size': batch_size, 'activation': conv_layer_activation, 'optimizer': optz_name, 
}

print('memory usage : {} GB'.format(get_model_memory_usage(batch_size=batch_size, model=model)))
note  = 'Major Tweaks #2(10+30+50+50) (activation:{}, opt:{}, filter_size:{}, Conv2D_counts:{}, FC_counts:{})'.format(
    conv_layer_activation, optz_name, filter_size, layer_counts['Conv2D'], layer_counts['Dense']
)
note

# note = 'Model 1: Default Original Params (10 Epoch)'
# note = 'Model 2: default model 64 batch size (10 Epoch)'
# note = 'Model 3: 128 batch size, with STG-Neterov (10 Epoch)'
# note = 'Model default (activation:{})'.format(conv_layer_activation)
# note = 'Model VGG-16'


try:
    history = model.fit(train_images,
                        train_labels,
                        epochs=epochs,
                        batch_size=batch_size,
                        validation_data=(val_images, val_labels),
                        shuffle=True)
    
    model_json = model.to_json()
    with open("model.json", "w") as json_file:
      json_file.write(model_json)
      # serialize weights to HDF5
    model.save_weights("model.h5")
    print("Saved model to disk")
    
except Exception as e:
    raise e

from keras.models import model_from_json
json_file = open('model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights("model.h5")
print("Loaded model from disk")

optz = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)
loaded_model.compile(loss='categorical_crossentropy', optimizer=optz, metrics=['accuracy'])

score = loaded_model.evaluate(val_images, val_labels, verbose=0)

print("%s: %.2f%%" % (loaded_model.metrics_names[1], score[1]*100))

pred = loaded_model.predict_classes(val_images)

import pandas as pd
pred = pd.DataFrame(pred)
pred.head()

count = 0
final_csv = pd.DataFrame()
dct_fn = {}
for line in open(path + 'val/val_annotations.txt'):
    [fn, classname, _ , _, _, _ ] = line.strip().split('\t')
    dct_fn[count] = fn
    count += 1

count = 0
dct_cn = {}
for class_path in train_dirs:
    class_name = class_path[-9:]
    images = glob.glob(class_path + '/images/*')
    dct_cn[count] = class_name
    count += 1

col1 = []
col2 = []
for i in range(len(pred)):
  val1 = dct_fn[pred.index[i]]
  val2 = dct_cn[int(pred.loc[i,:])]
  col1.append(val1)
  col2.append(val2)

final_csv = pd.DataFrame()
final_csv[0] = col1
final_csv[1] = col2

final_csv.head()

final_csv.to_csv('final.csv',index=False,header=False)

# from google.colab import files
# files.download('final.csv')

